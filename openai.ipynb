{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the API key as an environment variable\n",
    "os.environ['OPENAI_API_KEY'] = \"<Your Azure OpenAI API Key>\"\n",
    "\n",
    "print(os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_input = \"Blade Discovery\"\n",
    "UML_Diagram_1 = \"Activity Diagram\"\n",
    "UML_Diagram_2 = \"Class Diagram\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import fitz  # PyMuPDF\n",
    "from chromadb import Client, Embeddings, EmbeddingFunction, PersistentClient\n",
    "from chromadb.config import Settings\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "TEXT_EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "IMAGE_EMBEDDING_MODEL = \"image-embedding-1\"\n",
    "CHAT_MODEL = \"gpt-4.1\"\n",
    "API_URL = 'https://openaichatgpt-ms-epb1-xc.openai.azure.com/openai/deployments'\n",
    "API_KEY = os.getenv('OPENAI_API_KEY')  # Read API key from environment variable\n",
    "CHAT_API_VERSION = \"2025-01-01-preview\"\n",
    "EMBEDDING_API_VERSION = \"2024-02-01\"\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"API key not found. Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "HEADERS = {\n",
    "    'Authorization': f\"Bearer {API_KEY}\",\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "REQUIREMENT_METADATA_FILE = \"Requirement_pdf_metadata.json\"\n",
    "REFERENCE_DATA_METADATA_FILE = \"Reference_pdf_metadata.json\"\n",
    "GUIDELINE_DATA_METADATA_FILE = \"Guideline_pdf_metadata.json\"\n",
    "REFERENCE_CODE_METADATA_FILE = \"Reference_Code_metadata.json\"\n",
    "CODE_GUIDELINE_METADATA_FILE = \"Code_Guideline_pdf_metadata.json\"\n",
    "\n",
    "# Function to calculate MD5 hash of a PDF file\n",
    "def calculate_pdf_hash(pdf_path):\n",
    "    \"\"\"\n",
    "    Calculate the MD5 hash of a PDF file.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The file path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: The MD5 hash of the PDF file as a hexadecimal string.\n",
    "\n",
    "    Example:\n",
    "        >>> calculate_pdf_hash('example.pdf')\n",
    "        'd41d8cd98f00b204e9800998ecf8427e'\n",
    "    \"\"\"\n",
    "    hasher = hashlib.md5()\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        buf = f.read()\n",
    "        hasher.update(buf)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The file path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted text from the PDF file.\n",
    "\n",
    "    Example:\n",
    "        >>> extract_text_from_pdf('example.pdf')\n",
    "        'This is the extracted text from the PDF file.'\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    doc.close()\n",
    "    return text\n",
    "\n",
    "def read_source_code(file_path):\n",
    "    \"\"\"\n",
    "    Reads the content of a source code file and returns it as a string.\n",
    "    Args:\n",
    "        file_path (str): The path to the file to be read.\n",
    "    Returns:\n",
    "        str: The content of the file as a string.\n",
    "    Raises:\n",
    "        FileNotFoundError: If the file does not exist.\n",
    "        IOError: If there is an error reading the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "# Function to extract images from PDF\n",
    "def extract_images_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract images from a PDF file.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The file path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of PIL Image objects extracted from the PDF file.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    images = []\n",
    "    for page in doc:\n",
    "        for img in page.get_images(full=True):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            image_bytes = base_image[\"image\"]\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "            images.append(image)\n",
    "    doc.close()\n",
    "    return images\n",
    "\n",
    "# Split text into chunks\n",
    "def split_text_into_chunks(text, chunk_size=1000):\n",
    "    \"\"\"\n",
    "    Split text into chunks of a specified size.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be split into chunks.\n",
    "        chunk_size (int, optional): The size of each chunk. Default is 1000.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of text chunks.\n",
    "\n",
    "    Example:\n",
    "        >>> split_text_into_chunks('This is a long text that needs to be split into chunks.', chunk_size=10)\n",
    "        ['This is a ', 'long text ', 'that needs', ' to be spl', 'it into ch', 'unks.']\n",
    "    \"\"\"\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "# Embedding Function Class with Rate Limiting\n",
    "class MyEmbeddingFunction(EmbeddingFunction):\n",
    "    \"\"\"\n",
    "    A class to handle embedding functions with rate limiting.\n",
    "\n",
    "    Attributes:\n",
    "        batch_size (int): The size of each batch for processing.\n",
    "\n",
    "    Methods:\n",
    "        get_embedding(batch_data):\n",
    "            Sends a batch of document chunk request to the embedding API and returns the embeddings for the chunks.\n",
    "        \n",
    "        __call__(chunks):\n",
    "            Processes chunks in batches to reduce the number of API calls.\n",
    "        \n",
    "        __get_user_querry_embedding__(user_querry):\n",
    "            Retrieves the embedding for a single user query.\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size=5, max_retries=5, backoff_factor=2):\n",
    "        \"\"\"\n",
    "        Initializes the MyEmbeddingFunction with a specified batch size.\n",
    "\n",
    "        Args:\n",
    "            batch_size (int): The size of each batch for processing. Default is 5.\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.max_retries = max_retries\n",
    "        self.backoff_factor = backoff_factor\n",
    "\n",
    "    def get_embedding(self, batch_data):\n",
    "        \"\"\"\n",
    "        Helper function to send a batch request to the embedding API.\n",
    "\n",
    "        Args:\n",
    "            batch_data (list): A list of inputs for batch processing.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of embeddings if successful, otherwise None.\n",
    "        \"\"\"\n",
    "        data = {\n",
    "            'input': batch_data,  # Sending a list of inputs for batch processing\n",
    "            'dimensions': 1024\n",
    "        }\n",
    "        \n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                response = requests.post(f'{API_URL}/{TEXT_EMBEDDING_MODEL}/embeddings?api-version={EMBEDDING_API_VERSION}', headers=HEADERS, json=data)\n",
    "                response.raise_for_status()  # Raises an HTTPError if the response was unsuccessful\n",
    "                data_ = response.json()\n",
    "                \n",
    "                # Debugging: Print the response for troubleshooting\n",
    "                # print(\"API Response:\", data_)\n",
    "\n",
    "                # Extract embeddings if present\n",
    "                if 'data' in data_:\n",
    "                    # Flatten and validate\n",
    "                    embeddings = [item.get('embedding') for item in data_['data']]\n",
    "                    return embeddings\n",
    "                \n",
    "                print(\"Embedding not found in response\")\n",
    "                return None\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                if 'response' in locals() and response.status_code == 429:\n",
    "                    # Handle rate limiting\n",
    "                    print(f\"Rate limit exceeded. Retrying in {self.backoff_factor * (2 ** attempt)} seconds...\")\n",
    "                    time.sleep(self.backoff_factor * (2 ** attempt))\n",
    "                else:\n",
    "                    print(f\"Request failed: {e}\")\n",
    "                    return None\n",
    "            except KeyError as e:\n",
    "                print(f\"KeyError in response: {e}\")\n",
    "                return None\n",
    "        \n",
    "    def get_image_embedding(self, images):\n",
    "        \"\"\"\n",
    "        Helper function to send a batch of image data to the embedding API.\n",
    "\n",
    "        Args:\n",
    "            images (list): A list of PIL Image objects.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of embeddings if successful, otherwise None.\n",
    "        \"\"\"\n",
    "        descriptions = []\n",
    "\n",
    "        for image in images:\n",
    "            # Convert the image to base64\n",
    "            buffered = io.BytesIO()\n",
    "            image.save(buffered, format=\"PNG\")\n",
    "            image_base64 = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "            # Compose the payload\n",
    "            data = {\n",
    "                \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\n",
    "                                \"type\": \"text\",\n",
    "                                \"text\": \"Describe this image in detail. Make sure to include all the important details like text. If the image contains UML diagrams, understand and describe its components.\"\n",
    "                            },\n",
    "                            {\n",
    "                                \"type\": \"image_url\",\n",
    "                                \"image_url\": {\n",
    "                                    \"url\": f\"data:image/png;base64,{image_base64}\",\n",
    "                                    \"detail\": \"high\"\n",
    "                                }\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                \"max_tokens\": 500,\n",
    "                \"temperature\": 0.5,\n",
    "                \"top_p\": 0.9\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                response = requests.post(\n",
    "                    f'{API_URL}/{CHAT_MODEL}/chat/completions?api-version={CHAT_API_VERSION}',\n",
    "                    headers=HEADERS,\n",
    "                    json=data\n",
    "                )\n",
    "                response.raise_for_status()\n",
    "                data_ = response.json()\n",
    "                if 'choices' in data_ and len(data_['choices']) > 0:\n",
    "                    descriptions.append(data_['choices'][0]['message']['content'])\n",
    "                else:\n",
    "                    descriptions.append(None)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Failed to describe image: {e}\")\n",
    "                descriptions.append(None)\n",
    "\n",
    "        # Generate embeddings for the descriptions\n",
    "        text_embeddings = []\n",
    "        for description in descriptions:\n",
    "            if description:\n",
    "                text_embedding = self.__get_user_querry_embedding__(description)\n",
    "                text_embeddings.append(text_embedding)\n",
    "            else:\n",
    "                text_embeddings.append(None)\n",
    "\n",
    "        return text_embeddings\n",
    "\n",
    "    def __call__(self, chunks):\n",
    "        \"\"\"\n",
    "        Process chunks in batches to reduce the number of API calls.\n",
    "\n",
    "        Args:\n",
    "            chunks (list): A list of text chunks to be processed.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of embeddings corresponding to the chunks.\n",
    "        \"\"\"\n",
    "        embeddings = []\n",
    "        for i in range(0, len(chunks), self.batch_size):\n",
    "            batch = chunks[i:i + self.batch_size]\n",
    "            result = self.get_embedding(batch)\n",
    "            if result:\n",
    "                embeddings.extend(result)\n",
    "            else:\n",
    "                # If batch processing fails, fill with None to maintain alignment\n",
    "                embeddings.extend([None] * len(batch))\n",
    "        return embeddings\n",
    "\n",
    "    def __get_user_querry_embedding__(self, user_querry: str) -> Embeddings:\n",
    "        \"\"\"\n",
    "        Retrieves the embedding for a single user query.\n",
    "\n",
    "        Args:\n",
    "            user_querry (str): The user query string.\n",
    "\n",
    "        Returns:\n",
    "            list: The embedding for the user query as a list of floats, or None if unsuccessful.\n",
    "        \"\"\"\n",
    "        data = {\n",
    "            'input': user_querry,\n",
    "            'dimensions': 1024\n",
    "        }\n",
    "        \n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                response = requests.post(f'{API_URL}/{TEXT_EMBEDDING_MODEL}/embeddings?api-version={EMBEDDING_API_VERSION}', headers=HEADERS, json=data)\n",
    "                response.raise_for_status()\n",
    "                data_ = response.json()\n",
    "                if 'data' in data_ and len(data_['data']) > 0 and 'embedding' in data_['data'][0]:\n",
    "                    return data_['data'][0]['embedding']\n",
    "                return None\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                if response.status_code == 429:\n",
    "                    # Handle rate limiting\n",
    "                    print(f\"Rate limit exceeded. Retrying in {self.backoff_factor * (2 ** attempt)} seconds...\")\n",
    "                    time.sleep(self.backoff_factor * (2 ** attempt))\n",
    "                else:\n",
    "                    print(f\"Request failed: {e}\")\n",
    "                    return None\n",
    "            except KeyError as e:\n",
    "                print(f\"KeyError in response: {e}\")\n",
    "                return None\n",
    "\n",
    "# Initialize Chroma Client (new method)\n",
    "def init_chroma_client(collection_name):\n",
    "    \"\"\"\n",
    "    Initializes the Chroma client with default settings and ensures the collection is created or retrieved.\n",
    "\n",
    "    Returns:\n",
    "        client: The initialized Chroma client.\n",
    "        collection: The Chroma collection for storing embeddings.\n",
    "\n",
    "    Example:\n",
    "        client, collection = init_chroma_client()\n",
    "    \"\"\"\n",
    "    # Initialize with the new default settings\n",
    "    client = PersistentClient(path=f\"./persistent_dir_embeddings_{collection_name}\")\n",
    "    \n",
    "    # Ensure the collection is created or retrieved\n",
    "    collection = client.get_or_create_collection(name=collection_name, embedding_function=MyEmbeddingFunction())\n",
    "    \n",
    "    return client, collection\n",
    "\n",
    "# Load or initialize metadata\n",
    "def load_metadata(metadata_file):\n",
    "    \"\"\"\n",
    "    Loads metadata from a predefined file if it exists.\n",
    "\n",
    "    Returns:\n",
    "        dict: The loaded metadata as a dictionary. Returns an empty dictionary if the file does not exist.\n",
    "\n",
    "    Example:\n",
    "        metadata = load_metadata()\n",
    "    \"\"\"\n",
    "    if os.path.exists(metadata_file):\n",
    "        with open(metadata_file, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_metadata(metadata, metadata_file):\n",
    "    \"\"\"\n",
    "    Saves the provided metadata to a predefined file.\n",
    "\n",
    "    Parameters:\n",
    "        metadata (dict): The metadata to be saved.\n",
    "\n",
    "    Example:\n",
    "        save_metadata(metadata)\n",
    "    \"\"\"\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(metadata, f, indent=4)\n",
    "\n",
    "# Check if document embeddings already exist in Chroma\n",
    "def check_document_in_chroma(pdf_hash, collection):\n",
    "    \"\"\"\n",
    "    Checks if document embeddings already exist in Chroma for a given PDF hash.\n",
    "\n",
    "    Parameters:\n",
    "        pdf_hash (str): The hash of the PDF document.\n",
    "        collection: The Chroma collection.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the document embeddings exist, False otherwise.\n",
    "\n",
    "    Example:\n",
    "        exists = check_document_in_chroma(pdf_hash, collection)\n",
    "    \"\"\"\n",
    "    results = collection.get(\n",
    "        where={\"doc_hash\": pdf_hash}, \n",
    "        include=[\"documents\"]\n",
    "    )\n",
    "    \n",
    "    # If documents matching the hash are found, return True\n",
    "    return len(results['documents']) > 0\n",
    "\n",
    "# Check if document embeddings already exist in Chroma\n",
    "def check_document_in_chroma_metadata(pdf_hash, metadata):\n",
    "    \"\"\"\n",
    "    Checks if document embeddings already exist in the metadata for a given PDF hash.\n",
    "\n",
    "    Parameters:\n",
    "        pdf_hash (str): The hash of the PDF document.\n",
    "        metadata (dict): The metadata dictionary.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the document embeddings exist in the metadata, False otherwise.\n",
    "\n",
    "    Example:\n",
    "        exists = check_document_in_chroma_metadata(pdf_hash, metadata)\n",
    "    \"\"\"\n",
    "    return pdf_hash in metadata\n",
    "\n",
    "# Function to create embeddings for PDF chunks and store in Chroma\n",
    "def create_embeddings_for_pdf(pdf_path, collection, metadata, metadata_file):\n",
    "    \"\"\"\n",
    "    Creates embeddings for PDF chunks and stores them in Chroma.\n",
    "\n",
    "    Parameters:\n",
    "        pdf_path (str): The path to the PDF document.\n",
    "        collection: The Chroma collection.\n",
    "        metadata (dict): The metadata dictionary.\n",
    "\n",
    "    Example:\n",
    "        create_embeddings_for_pdf(\"example.pdf\", collection, metadata)\n",
    "    \"\"\"\n",
    "    pdf_hash = calculate_pdf_hash(pdf_path)\n",
    "    \n",
    "    # Check if document embeddings already exist\n",
    "    # if check_document_in_chroma(pdf_hash, collection):\n",
    "    #     print(f\"Document '{pdf_path}' unchanged. Using existing embeddings.\")\n",
    "    #     return\n",
    "\n",
    "    # Check if document is unchanged\n",
    "    if check_document_in_chroma_metadata(pdf_hash, metadata):\n",
    "        print(f\"Document '{pdf_path}' unchanged. Skipping re-embedding.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Processing new or updated document: {pdf_path}\")\n",
    "    \n",
    "    # Load the PDF document\n",
    "    # Extract text from the entire PDF\n",
    "    full_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    # Split the extracted text into chunks\n",
    "    chunks = split_text_into_chunks(full_text, chunk_size=1000)  # You can adjust the chunk_size as needed\n",
    "\n",
    "    #extract images\n",
    "    images = extract_images_from_pdf(pdf_path)\n",
    "    \n",
    "    # Initialize embedding function (assuming you're using Ollama or any other embedding function)\n",
    "    embF = MyEmbeddingFunction(batch_size=10)\n",
    "\n",
    "    # Generate embeddings for all chunks in batches\n",
    "    embeddings = embF.__call__(chunks)\n",
    "    \n",
    "    # Add documents to Chroma collection\n",
    "    for i, embedding in enumerate(embeddings):\n",
    "        if embedding is not None:\n",
    "            collection.add(\n",
    "                documents=[chunks[i]],\n",
    "                metadatas=[{\n",
    "                    'chunk_id': i,\n",
    "                    'doc_hash': pdf_hash,\n",
    "                    'source': pdf_path\n",
    "                }],\n",
    "                embeddings=[embedding],\n",
    "                ids=[f\"{pdf_path}_chunk{i}\"]\n",
    "            )\n",
    "    \n",
    "    if images:\n",
    "        #Generate Embeddings for Images:\n",
    "        image_embeddings = embF.get_image_embedding(images)\n",
    "        for i, embedding in enumerate(image_embeddings):\n",
    "            if embedding is not None:\n",
    "                collection.add(\n",
    "                    documents=[f\"Image {i} from {pdf_path}\"],\n",
    "                    metadatas=[{\n",
    "                        'image_id': i,\n",
    "                        'doc_hash': pdf_hash,\n",
    "                        'source': pdf_path\n",
    "                    }],\n",
    "                    embeddings=[embedding],\n",
    "                    ids=[f\"{pdf_path}_image{i}\"]\n",
    "                )\n",
    "    \n",
    "    # Update metadata\n",
    "    metadata[pdf_hash] = {'path': pdf_path}\n",
    "    save_metadata(metadata, metadata_file)\n",
    "    print(f\"Embeddings for '{pdf_path}' created successfully.\")\n",
    "\n",
    "# Function to process header and source files\n",
    "def process_reference_code(directory, collection, metadata_file):\n",
    "    \"\"\"\n",
    "    Processes reference code files in a given directory by generating embeddings for their content\n",
    "    and storing the embeddings in a specified collection.\n",
    "    Args:\n",
    "        directory (str): The root directory containing the 'inc' and 'src' subdirectories \n",
    "                         with header (.h) and source (.c) files respectively.\n",
    "        collection (object): The collection object where embeddings will be stored. \n",
    "                             It should support the `add` method for adding documents, metadata, and embeddings.\n",
    "        metadata_file (str): The path to the metadata file used to track processed files and their hashes.\n",
    "    Workflow:\n",
    "        1. Load metadata from the specified metadata file.\n",
    "        2. Identify all header (.h) and source (.c) files in the 'inc' and 'src' subdirectories.\n",
    "        3. Calculate a hash for each file to determine if it has been processed before.\n",
    "        4. Skip processing for files that are unchanged based on their hash.\n",
    "        5. For each unprocessed file:\n",
    "            - Read the file content and split it into chunks.\n",
    "            - Generate embeddings for each chunk using a custom embedding function.\n",
    "            - Add the embeddings, along with metadata, to the specified collection.\n",
    "        6. Update the metadata file with the hash and path of the processed file.\n",
    "    Notes:\n",
    "        - The function assumes the existence of helper functions such as `load_metadata`, \n",
    "          `calculate_pdf_hash`, `check_document_in_chroma_metadata`, `split_text_into_chunks`, \n",
    "          `MyEmbeddingFunction`, and `save_metadata`.\n",
    "        - The `chunk_size` for splitting text and `batch_size` for embedding generation are hardcoded.\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified metadata file or any required subdirectory/file is not found.\n",
    "        Exception: For any other errors encountered during file processing or embedding generation.\n",
    "    Example:\n",
    "        process_reference_code(\n",
    "            directory=\"/path/to/codebase\",\n",
    "            collection=my_collection,\n",
    "            metadata_file=\"/path/to/metadata.json\"\n",
    "    \"\"\"\n",
    "    metadata = load_metadata(metadata_file)\n",
    "    \n",
    "    # List all header and source files in the directory\n",
    "    header_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.h')]\n",
    "    source_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.c')]\n",
    "    \n",
    "    # Combine all files to process\n",
    "    all_files = header_files + source_files\n",
    "    \n",
    "    for file_path in all_files:\n",
    "        # Calculate hash to check if the file has changed\n",
    "        file_hash = calculate_pdf_hash(file_path)  # Reuse the hash function for consistency\n",
    "        \n",
    "        # Skip if already processed\n",
    "        if check_document_in_chroma_metadata(file_hash, metadata):\n",
    "            print(f\"File '{file_path}' unchanged. Skipping re-embedding.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        \n",
    "        # Read and split the file content into chunks\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            file_content = f.read()\n",
    "        chunks = split_text_into_chunks(file_content, chunk_size=1000)\n",
    "        \n",
    "        # Generate embeddings for the chunks\n",
    "        embF = MyEmbeddingFunction(batch_size=10)\n",
    "        embeddings = embF.__call__(chunks)\n",
    "        \n",
    "        # Add embeddings to the collection\n",
    "        for i, embedding in enumerate(embeddings):\n",
    "            if embedding is not None:\n",
    "                collection.add(\n",
    "                    documents=[chunks[i]],\n",
    "                    metadatas=[{\n",
    "                        'chunk_id': i,\n",
    "                        'doc_hash': file_hash,\n",
    "                        'source': file_path\n",
    "                    }],\n",
    "                    embeddings=[embedding],\n",
    "                    ids=[f\"{file_path}_chunk{i}\"]\n",
    "                )\n",
    "        \n",
    "        # Update metadata\n",
    "        metadata[file_hash] = {'path': file_path}\n",
    "        save_metadata(metadata, metadata_file)\n",
    "        print(f\"Embeddings for '{file_path}' created successfully.\")\n",
    "\n",
    "# Remove embeddings for deleted PDFs\n",
    "def remove_deleted_pdfs_from_chroma(directory, collection, metadata, metadata_file):\n",
    "    \"\"\"\n",
    "    Remove embeddings for deleted PDFs from the collection.\n",
    "\n",
    "    This function performs the following tasks:\n",
    "    1. Identifies PDF files that have been deleted from the \"docs\" directory.\n",
    "    2. Removes the corresponding entries from the collection and metadata.\n",
    "\n",
    "    Parameters:\n",
    "    collection (object): The collection object from which the PDF embeddings and metadata will be removed.\n",
    "    metadata (dict): A dictionary containing metadata about the PDFs, where the key is the PDF hash and the value is a dictionary with PDF information.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Detailed Steps:\n",
    "    1. Identify Existing Files: The function creates a set of existing PDF files in the \"docs\" directory.\n",
    "    2. Identify Deleted Files: It then identifies which PDFs have been deleted by comparing the existing files with the metadata.\n",
    "    3. Remove Deleted Files: For each deleted PDF, the function removes the corresponding entry from the collection and metadata, and prints a message indicating the removal.\n",
    "    4. Save Updated Metadata: Finally, the function saves the updated metadata.\n",
    "\n",
    "    Notes:\n",
    "    - Ensure that the `save_metadata` function is defined and imported in the script.\n",
    "    - The \"docs\" directory should contain only the PDF files that are currently in use.\n",
    "    \"\"\"\n",
    "    existing_files = {f for f in os.listdir(directory) if f.endswith(\".pdf\")}\n",
    "    hashes_to_remove = [\n",
    "        pdf_hash for pdf_hash, info in metadata.items()\n",
    "        if os.path.basename(info['path']) not in existing_files\n",
    "    ]\n",
    "\n",
    "    for pdf_hash in hashes_to_remove:\n",
    "        print(f\"Removing deleted document with hash: {pdf_hash}\")\n",
    "        collection.delete(where={\"doc_hash\": pdf_hash})\n",
    "        del metadata[pdf_hash]\n",
    "    \n",
    "    save_metadata(metadata, metadata_file)\n",
    "    \n",
    "# Process all PDFs in the docs/ directory\n",
    "def process_all_pdfs(directory, collection, metadata_file):\n",
    "    \"\"\"\n",
    "    Process all PDFs in the specified directory.\n",
    "\n",
    "    This function performs the following tasks:\n",
    "    1. Loads metadata.\n",
    "    2. Removes entries for deleted PDFs from a collection.\n",
    "    3. Creates embeddings for each PDF file in the directory and updates the collection with the metadata.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The path to the directory containing the PDF files to be processed.\n",
    "    collection (object): The collection object where the PDF embeddings and metadata will be stored.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example Usage:\n",
    "    process_all_pdfs('docs/', my_collection)\n",
    "\n",
    "    Detailed Steps:\n",
    "    1. Load Metadata: The function starts by loading metadata using the `load_metadata` function.\n",
    "    2. Remove Deleted PDFs: It then removes entries for deleted PDFs from the collection using the `remove_deleted_pdfs_from_chroma` function.\n",
    "    3. Process PDF Files: The function lists all PDF files in the specified directory and iterates over each file. For each PDF file, it creates embeddings using the `create_embeddings_for_pdf` function and updates the collection with the metadata.\n",
    "\n",
    "    Notes:\n",
    "    - Ensure that the `load_metadata`, `remove_deleted_pdfs_from_chroma`, and `create_embeddings_for_pdf` functions are defined and imported in the script.\n",
    "    - The `directory` should contain only PDF files that need to be processed.\n",
    "    \"\"\"\n",
    "    metadata = load_metadata(metadata_file)\n",
    "    \n",
    "    # Remove entries for deleted PDFs\n",
    "    remove_deleted_pdfs_from_chroma(directory, collection, metadata, metadata_file)\n",
    "\n",
    "    pdf_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.pdf')]\n",
    "    for pdf_path in pdf_files:\n",
    "        create_embeddings_for_pdf(pdf_path, collection, metadata, metadata_file)\n",
    "\n",
    "# Embedding user query and finding the best matching chunk\n",
    "def find_relevant_chunk(user_query, collection):\n",
    "    \"\"\"\n",
    "    Embed the user query and find the best matching chunk in the collection.\n",
    "\n",
    "    This function performs the following tasks:\n",
    "    1. Generates an embedding for the user query.\n",
    "    2. Queries the collection to find the best matching chunks based on the query embedding.\n",
    "\n",
    "    Parameters:\n",
    "    user_query (str): The user's query string that needs to be embedded and matched.\n",
    "    collection (object): The collection object where the embeddings and documents are stored.\n",
    "\n",
    "    Returns:\n",
    "    list or None: A list of documents that best match the user query, or None if no matches are found or if the embedding generation fails.\n",
    "\n",
    "    Detailed Steps:\n",
    "    1. Generate Query Embedding: The function uses `MyEmbeddingFunction` to generate an embedding for the user query.\n",
    "    2. Check Embedding: It checks if the embedding generation was successful. If not, it prints an error message and returns None.\n",
    "    3. Query Collection: The function queries the collection with the generated embedding to find the top 100 matching results.\n",
    "    4. Return Results: If matching documents are found, it returns the list of documents. Otherwise, it returns None.\n",
    "\n",
    "    Notes:\n",
    "    - Ensure that the `MyEmbeddingFunction` class and its `__get_user_querry_embedding__` method are defined and imported in the script.\n",
    "    - The `collection` object should support the `query` method with the specified parameters.\n",
    "    \"\"\"\n",
    "    embF = MyEmbeddingFunction()\n",
    "    query_embedding = embF.__get_user_querry_embedding__(user_query)\n",
    "    \n",
    "    # Check if embedding is None\n",
    "    if query_embedding is None:\n",
    "        print(\"Failed to generate embedding for the query.\")\n",
    "        return None\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=10\n",
    "    )\n",
    "    \n",
    "    if results and 'documents' in results and len(results['documents']) > 0:\n",
    "        return results['documents']\n",
    "    return None\n",
    "\n",
    "# Prompting the model for text generation\n",
    "def prompt_model(messages, model: str = CHAT_MODEL, max_tokens: int = 5000, temperature: float = 0.5, top_p: float = 0.7, max_retries: int = 5, backoff_factor: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    Prompt the model for text generation.\n",
    "\n",
    "    This function sends a prompt to a specified model and returns the generated text.\n",
    "\n",
    "    Parameters:\n",
    "    prompt_text (str): The text prompt to send to the model.\n",
    "    model (str): The model to use for text generation. Default is CHAT_MODEL.\n",
    "    max_tokens (int): The maximum number of tokens to generate. Default is 500.\n",
    "    temperature (float): The sampling temperature. Default is 0.2.\n",
    "    top_k (int): The number of highest probability vocabulary tokens to keep for top-k filtering. Default is 50.\n",
    "    top_p (float): The cumulative probability for top-p (nucleus) sampling. Default is 0.7.\n",
    "\n",
    "    Returns:\n",
    "    str or None: The generated text if the request is successful and the response contains text, otherwise None.\n",
    "\n",
    "    Detailed Steps:\n",
    "    1. Prepare Request Data: The function prepares the data dictionary with the model parameters and prompt text.\n",
    "    2. Send Request: It sends a POST request to the API endpoint for text generation.\n",
    "    3. Check Response: The function checks if the response status is 200 (OK) and if the response contains generated text.\n",
    "    4. Return Generated Text: If the response is valid and contains text, it returns the generated text. Otherwise, it returns None.\n",
    "\n",
    "    Notes:\n",
    "    - Ensure that the `requests` library is imported and the `API_URL` and `HEADERS` constants are defined in the script.\n",
    "    - The model parameter should be a valid model identifier recognized by the API.\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        'messages': messages,\n",
    "        'max_tokens': max_tokens,\n",
    "        'temperature': temperature,\n",
    "        'top_p': top_p,\n",
    "    }\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(f'{API_URL}/{CHAT_MODEL}/chat/completions?api-version={CHAT_API_VERSION}', headers=HEADERS, json=data)\n",
    "            response.raise_for_status()  # Raises an HTTPError if the response was unsuccessful\n",
    "            data_ = response.json()\n",
    "            \n",
    "            # Debugging: Print the response for troubleshooting\n",
    "            print(\"API Response:\", data_)\n",
    "\n",
    "            if 'choices' in data_ and len(data_['choices']) > 0:\n",
    "                return data_['choices'][0]['message']['content']\n",
    "            return None\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            if isinstance(e, requests.exceptions.HTTPError) and e.response is not None and e.response.status_code == 429:\n",
    "                # Handle rate limiting\n",
    "                print(f\"Rate limit exceeded. Retrying in {backoff_factor * (2 ** attempt)} seconds...\")\n",
    "                time.sleep(backoff_factor * (2 ** attempt))\n",
    "            else:\n",
    "                print(f\"Request failed: {e}\")\n",
    "                return None\n",
    "        except KeyError as e:\n",
    "            print(f\"KeyError in response: {e}\")\n",
    "            return None\n",
    "    \n",
    "def summarize_requirements(feature_query, collection):\n",
    "    relevant_chunks = find_relevant_chunk(feature_query, collection)\n",
    "    if not relevant_chunks:\n",
    "        print(\"No relevant requirements found.\")\n",
    "        return None\n",
    "    \n",
    "    # Define the system and user messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "            You are a highly skilled AI assistant specializing in summarizing technical requirements. You are provided with Requirement Chunks delimited by tripple backticks.\n",
    "            Your task is to:\n",
    "            1. Identify and categorize all functional and non-functional requirements.\n",
    "            2. Highlight any constraints, dependencies, or assumptions that may impact system design.\n",
    "            3. Ignore unrelated or ambiguous information and ensure consistency.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            Requirements:\n",
    "            ```{relevant_chunks}```\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    summary = prompt_model(messages)\n",
    "    return summary\n",
    "\n",
    "def extract_design_information(requirements_summary, collection):\n",
    "    relevant_chunks = find_relevant_chunk(requirements_summary, collection)\n",
    "    if not relevant_chunks:\n",
    "        print(\"No relevant design information found.\")\n",
    "        return None\n",
    "    \n",
    "    # Define the system and user messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "            You are a highly skilled AI assistant specializing in understanding Software Architechture. You are provided with Requirements and Information from Software Architechture delimited by tripple backticks.\n",
    "            Your task is to:\n",
    "            1. First understand the requirements and identify all the critical / important points mentioned in the requirements.\n",
    "            2. Next, understand the extracted Software Architecture and identify relevant API functions, parameters, protocols, and constraints.\n",
    "            3. Next Combine the understanding of the Software Architechture and the input Requirements into a unified view. If needed, bring out the delta information (or additional information) that is needed to realize the input Requirements.\n",
    "            4. Make sure that the generated output addresses all the requirements and is consistent with the Software Architecture.\n",
    "            5. Ignore unrelated or ambiguous information and ensure consistency.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            Requirements:\n",
    "            ```{requirements_summary}```\n",
    "            Software Architecture:\n",
    "            ```{relevant_chunks}```\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    design_info = prompt_model(messages)\n",
    "    return design_info\n",
    "\n",
    "def extract_code_information(requirements_summary, reference_code_collection):\n",
    "    \"\"\"\n",
    "    Extract relevant code information from the reference code collection based on the requirements summary.\n",
    "\n",
    "    Args:\n",
    "        requirements_summary (str): The summarized requirements.\n",
    "        reference_code_collection: The Chroma collection containing reference code embeddings.\n",
    "\n",
    "    Returns:\n",
    "        str: Relevant code information as a string, or None if no relevant code is found.\n",
    "    \"\"\"\n",
    "    relevant_chunks = find_relevant_chunk(requirements_summary, reference_code_collection)\n",
    "    if not relevant_chunks:\n",
    "        print(\"No relevant code information found.\")\n",
    "        return None\n",
    "\n",
    "    # Define the system and user messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"\n",
    "            You are a highly skilled AI assistant specializing in understanding Software Designs from the Code. You are provided with Requirements and Code Information delimited by tripple backticks.\n",
    "            Your task is to:\n",
    "            1. First understand the requirements and identify all the critical / important points mentioned in the requirements.\n",
    "            2. Next, understand the extracted Code Information and in your understanding include all relevant API functions, parameters, protocols, and constraints.\n",
    "            3. Next Combine the understanding of the extracted Code Information and the input Requirements into a unified view. If needed, bring out the delta information (or additional information) that is needed to realize the input Requirements.\n",
    "            4. Make sure that the generated output addresses all the requirements and is consistent with the extracted Code Information.\n",
    "            5. Ignore unrelated or ambiguous information and ensure consistency.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            Requirements:\n",
    "            ```{requirements_summary}```\n",
    "            Code Information:\n",
    "            ```{relevant_chunks}```\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    code_design_info = prompt_model(messages)\n",
    "    return code_design_info\n",
    "\n",
    "def create_uml_design(UML_Diagram, design_info, code_design_info, design_querry, uml_guidelines_collection):\n",
    "    uml_guidelines = find_relevant_chunk(design_querry, uml_guidelines_collection)\n",
    "    if not uml_guidelines:\n",
    "        print(\"No UML design guidelines found.\")\n",
    "        return None\n",
    "    \n",
    "    # Define the system and user messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "            You are a highly skilled AI assistant specializing in creating Software UML designs.\n",
    "            Your task is to:\n",
    "            1. Create the requested ({UML_Diagram}) based on the Design information, Code Information and UML design guidelines delimited by tripple backticks.\n",
    "            2. Make sure all the identified API Functions, from the Design Information and the Code Information are included in the UML Design.\n",
    "            3. Provide PlantUML codes for each UML diagram.\n",
    "            4. Provide a detailed explanation of the requested PlantUML diagrams.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            Design Information:\n",
    "            ```{design_info}```\n",
    "            Code Information:\n",
    "            ```{code_design_info}```\n",
    "            UML Design Guidelines:\n",
    "            ```{uml_guidelines}```\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    uml_design = prompt_model(messages)\n",
    "    return uml_design\n",
    "\n",
    "def generate_code_from_design(uml_design_1, uml_design_2, user_querry, code_guideline_collection):\n",
    "    code_guidelines = find_relevant_chunk(user_querry, code_guideline_collection)\n",
    "    if not code_guidelines:\n",
    "        print(f\"No Code guidelines specific to the user querry: {user_querry} found.\")\n",
    "        return None\n",
    "    \n",
    "    # Define the system and user messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"\"\"\n",
    "            You are a highly skilled AI assistant specializing in creating source code by understanding the input UML Designs.\n",
    "            Your task is to:\n",
    "            1. Generate all the required source Code (.c and .h files), and also the main function, based on your understanding of the Design Information 1 and Design Information 2 delimited by tripple backticks.\n",
    "            2. Make sure all the identified API Functions, from both the Design Informations are included in your generated Code.\n",
    "            3. Make sure the generated source code adheres to the Coding Guidelines delimited by tripple backticks.\n",
    "            \"\"\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "            Design Information 1:\n",
    "            ```{uml_design_1}```\n",
    "            Design Information 2:\n",
    "            ```{uml_design_2}```\n",
    "            Coding Guidelines:\n",
    "            ```{code_guidelines}```\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    source_Code = prompt_model(messages)\n",
    "    return source_Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req_directory = \"Requirement_Docs\"\n",
    "desgn_directory = \"Reference_Docs\"\n",
    "reference_code_directory = \"ReferenceCode_Docs\"\n",
    "Design_guideline_directory = \"Guideline_Docs\"\n",
    "coding_guideline_directory = \"Coding_Guideline_Docs\"\n",
    "\n",
    "# Initialize Chroma client and collection for Requirement Documents\n",
    "Reqclient, req_collection = init_chroma_client(\"reqs\")\n",
    "\n",
    "# Initialize Chroma client and collection for Reference Documents\n",
    "Desgnclient, desgn_collection = init_chroma_client(\"refs\")\n",
    "\n",
    "# Initialize Chroma client and collection for guideline Documents\n",
    "guidelineclient, guideline_collection = init_chroma_client(\"UML\")\n",
    "\n",
    "# Initialize Chroma client and collection for Reference Code\n",
    "ReferenceCodeClient, reference_code_collection = init_chroma_client(\"code\")\n",
    "\n",
    "# Initialize Chroma client and collection for Coding Guideline Documents\n",
    "CodeGuidelineClient, code_guideline_collection = init_chroma_client(\"codeGuideline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all Requirement PDFs in the specified directory\n",
    "process_all_pdfs(req_directory, req_collection, REQUIREMENT_METADATA_FILE)\n",
    "\n",
    "# Process all Requirement PDFs in the specified directory\n",
    "process_all_pdfs(desgn_directory, desgn_collection, REFERENCE_DATA_METADATA_FILE)\n",
    "process_all_pdfs(Design_guideline_directory, guideline_collection, GUIDELINE_DATA_METADATA_FILE)\n",
    "\n",
    "# Process all files in the ReferenceCode folder\n",
    "process_reference_code(reference_code_directory, reference_code_collection, REFERENCE_CODE_METADATA_FILE)\n",
    "\n",
    "process_all_pdfs(coding_guideline_directory, code_guideline_collection, CODE_GUIDELINE_METADATA_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract and Summarize Requirements\n",
    "feature_query = f\"Extract all requirements related to {feature_input}.\"\n",
    "requirements_summary = summarize_requirements(feature_query, req_collection)\n",
    "print(\"Requirements Summary:\", requirements_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Extract Relevant Design Information\n",
    "design_info = extract_design_information(requirements_summary, desgn_collection)\n",
    "print(\"Design Information:\", design_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Extract Relevant Design information from Code.\n",
    "code_design_info = extract_code_information(requirements_summary, reference_code_collection)\n",
    "print(\"Code Design Information: \", code_design_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Create UML Design\n",
    "design_querry = f\"Extract the guidelines related to {UML_Diagram_1}\"\n",
    "uml_design_1 = create_uml_design(UML_Diagram_1, design_info, code_design_info, design_querry, guideline_collection)\n",
    "print(\"UML Design:\", uml_design_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create UML Design\n",
    "design_querry = f\"Extract the guidelines related to {UML_Diagram_2}\"\n",
    "uml_design_2 = create_uml_design(UML_Diagram_2, design_info, code_design_info, design_querry, guideline_collection)\n",
    "print(\"UML Design:\", uml_design_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step5: Generate Code from the Design\n",
    "code_guideline_input_querry = \"identify all the important guidelines related to C Coding\"\n",
    "generated_code = generate_code_from_design(uml_design_1, uml_design_2, code_guideline_input_querry, code_guideline_collection)\n",
    "print(\"Generated Source Code:\", generated_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myJupyterKernel",
   "language": "python",
   "name": "myjupyterkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
